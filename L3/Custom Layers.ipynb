{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layers\n",
    "\n",
    "This exercise is adapted from [this repository](https://github.com/david-drew/OpenVINO-Custom-Layers).\n",
    "\n",
    "Note that the classroom workspace is running OpenVINO 2019.r3, while this exercise was originally created for 2019.r2. This exercise will work appropriately in the workspace, but there may be some other differences you need to account for if you use a custom layer yourself.\n",
    "\n",
    "The below steps will walk you through the full walkthrough of creating a custom layer; as such, there is not a related solution video. Note that custom layers is an advanced topic, and one that is not expected to be used often (if at all) in most use cases of the OpenVINO toolkit. This exercise is meant to introduce you to the concept, but you won't need to use it again in the rest of this course.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Custom Layer: The Hyperbolic Cosine (cosh) Function\n",
    "We will follow the steps involved for implementing a custom layer using the simple hyperbolic cosine (cosh) function. The cosh function is mathematically calculated as:\n",
    "> `cosh(x) = (e^x + e^-x) / 2`\n",
    "\n",
    "### Build the Model\n",
    "First, export the below paths to shorten some of what you need to enter later:\n",
    "\n",
    "```sh\n",
    "export CLWS=/home/workspace/cl_tutorial\n",
    "export CLT=$CLWS/OpenVINO-Custom-Layers\n",
    "```\n",
    "\n",
    "Then run the following to create the TensorFlow model including the cosh layer.\n",
    "\n",
    "```sh\n",
    "mkdir $CLWS/tf_model\n",
    "python $CLT/create_tf_model/build_cosh_model.py $CLWS/tf_model\n",
    "```\n",
    "You should receive a message similar to:\n",
    "\n",
    "```sh\n",
    "Model saved in path: /tf_model/model.ckpt\n",
    "```\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the <i>cosh</i> Custom Layer\n",
    "### Generate the Extension Template Files Using the Model Extension Generator\n",
    "\n",
    "We will use the Model Extension Generator tool to automatically create templates for all the extensions needed by the Model Optimizer to convert and the Inference Engine to execute the custom layer. The extension template files will be partially replaced by Python and C++ code to implement the functionality of `cosh` as needed by the different tools. To create the four extensions for the `cosh` custom layer, we run the Model Extension Generator with the following options:\n",
    "\n",
    "- `--mo-tf-ext` = Generate a template for a Model Optimizer TensorFlow extractor\n",
    "- `--mo-op` = Generate a template for a Model Optimizer custom layer operation\n",
    "- `--ie-cpu-ext` = Generate a template for an Inference Engine CPU extension\n",
    "- `--ie-gpu-ext` = Generate a template for an Inference Engine GPU extension\n",
    "- `--output_dir` = set the output directory. Here we are using `$CLWS/cl_cosh` as the target directory to store the output from the Model Extension Generator.\n",
    "\n",
    "To create the four extension templates for the `cosh` custom layer, given we are in the `$CLWS` directory, we run the command:\n",
    "```sh\n",
    "mkdir cl_cosh\n",
    "```\n",
    "<hr>\n",
    "\n",
    "```sh\n",
    "python /opt/intel/openvino/deployment_tools/tools/extension_generator/extgen.py new --mo-tf-ext --mo-op --ie-cpu-ext --ie-gpu-ext --output_dir=$CLWS/cl_cosh\n",
    "```\n",
    "\n",
    "The Model Extension Generator will start in interactive mode and prompt us with questions about the custom layer to be generated. Use the text between the `[]`'s to answer each of the Model Extension Generator questions as follows:\n",
    "\n",
    "```\n",
    "Enter layer name: \n",
    "[cosh]\n",
    "\n",
    "Do you want to automatically parse all parameters from the model file? (y/n)\n",
    "...\n",
    "[n]\n",
    "\n",
    "Enter all parameters in the following format:\n",
    "...\n",
    "Enter 'q' when finished:\n",
    "[q]\n",
    "\n",
    "Do you want to change any answer (y/n) ? Default 'no'\n",
    "[n]\n",
    "\n",
    "Do you want to use the layer name as the operation name? (y/n)\n",
    "[y]\n",
    "\n",
    "Does your operation change shape? (y/n)  \n",
    "[n]\n",
    "\n",
    "Do you want to change any answer (y/n) ? Default 'no'\n",
    "[n]\n",
    "```\n",
    "<hr>\n",
    "\n",
    "When complete, the output text will appear similar to:\n",
    "\n",
    "```\n",
    "Stub file for TensorFlow Model Optimizer extractor is in /home/<user>/cl_tutorial/cl_cosh/user_mo_extensions/front/tf folder\n",
    "Stub file for the Model Optimizer operation is in /home/<user>/cl_tutorial/cl_cosh/user_mo_extensions/ops folder\n",
    "Stub files for the Inference Engine CPU extension are in /home/<user>/cl_tutorial/cl_cosh/user_ie_extensions/cpu folder\n",
    "Stub files for the Inference Engine GPU extension are in /home/<user>/cl_tutorial/cl_cosh/user_ie_extensions/gpu folder\n",
    "```\n",
    "<hr>\n",
    "Template files (containing source code stubs) that may need to be edited have just been created in the following locations:\n",
    "\n",
    "\n",
    "<b>TensorFlow Model Optimizer extractor extension:</b>\n",
    "    - $CLWS/cl_cosh/user_mo_extensions/front/tf/\n",
    "    - cosh_ext.py\n",
    "    \n",
    "<b>Model Optimizer operation extension:</b>\n",
    "     - $CLWS/cl_cosh/user_mo_extensions/ops\n",
    "     - cosh.py\n",
    "     \n",
    "<b>Inference Engine CPU extension:</b>\n",
    "     - $CLWS/cl_cosh/user_ie_extensions/cpu\n",
    "     - ext_cosh.cpp\n",
    "     - CMakeLists.txt\n",
    "     \n",
    "<b>Inference Engine GPU extension:</b>\n",
    "     - $CLWS/cl_cosh/user_ie_extensions/gpu\n",
    "     - cosh_kernel.cl\n",
    "     - cosh_kernel.xml\n",
    "     \n",
    "<hr>\n",
    "\n",
    "Instructions on editing the template files are provided in later parts of this tutorial.\n",
    "For reference, or to copy to make the changes quicker, pre-edited template files are provided by the tutorial in the `$CLT` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Model Optimizer to Generate IR Files Containing the Custom Layer\n",
    "We will now use the generated extractor and operation extensions with the Model Optimizer to generate the model IR files needed by the Inference Engine. The steps covered are:\n",
    "\n",
    "    1. Edit the extractor extension template file (already done - we will review it here)\n",
    "    2. Edit the operation extension template file (already done - we will review it here)\n",
    "    3. Generate the Model IR Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
