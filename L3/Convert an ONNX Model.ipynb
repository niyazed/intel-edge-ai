{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert an ONNX Model\n",
    "Link - https://docs.openvinotoolkit.org/2018_R5/_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_ONNX.html\n",
    "\n",
    "The process for converting an ONNX model is again quite similar to the previous two, although ONNX does not have any ONNX-specific arguments to the Model Optimizer. So, you’ll only have the general arguments for items like changing the precision.\n",
    "\n",
    "Additionally, if you are working with PyTorch or Apple ML models, they need to be converted to ONNX format first, which is done outside of the OpenVINO™ Toolkit. See the link further down on this page if you are interested in doing so.\n",
    "\n",
    "<hr>\n",
    "\n",
    "#### 1. Download the model\n",
    "    > wget https://s3.amazonaws.com/download.onnx/models/opset_8/bvlc_alexnet.tar.gz\n",
    "\n",
    "#### 2. Extract\n",
    "    > tar -xvf bvlc_alexnet.tar.gz\n",
    "\n",
    "#### 3.  Write `tree` in CLI\n",
    "\n",
    "    ├── bvlc_alexnet\n",
    "    │   ├── model.onnx\n",
    "    │   ├── test_data_0.npz\n",
    "    │   ├── test_data_1.npz\n",
    "    │   ├── test_data_2.npz\n",
    "    │   ├── test_data_set_0\n",
    "    │   │   ├── input_0.pb\n",
    "    │   │   └── output_0.pb\n",
    "    │   ├── test_data_set_1\n",
    "    │   │   ├── input_0.pb\n",
    "    │   │   └── output_0.pb\n",
    "    │   ├── test_data_set_2\n",
    "    │   │   ├── input_0.pb\n",
    "    │   │   └── output_0.pb\n",
    "    │   ├── test_data_set_3\n",
    "    │   │   ├── input_0.pb\n",
    "    │   │   └── output_0.pb\n",
    "    │   ├── test_data_set_4\n",
    "    │   │   ├── input_0.pb\n",
    "    │   │   └── output_0.pb\n",
    "    │   └── test_data_set_5\n",
    "    │       ├── input_0.pb\n",
    "    │       └── output_0.pb\n",
    "\n",
    "#### 4. Convert\n",
    "    > python3 $MOD_OPT/mo_onnx.py --input_model bvlc_alexnet/model.onnx\n",
    "    \n",
    "    ....\n",
    "    ....\n",
    "    \n",
    "    [ SUCCESS ] Generated IR model.\n",
    "    [ SUCCESS ] XML file: /home/workspace/./model.xml\n",
    "    [ SUCCESS ] BIN file: /home/workspace/./model.bin\n",
    "    [ SUCCESS ] Total execution time: 4.69 seconds.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### PyTorch to ONNX\n",
    "\n",
    "If you are interested in converting a PyTorch model using ONNX for use with the OpenVINO™ Toolkit, check out this [https://michhar.github.io/convert-pytorch-onnx/](https://michhar.github.io/convert-pytorch-onnx/) for the steps to do so. From there, you can follow the steps for ONNX models to get an Intermediate Representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
